---
title: 'Blog Post number 1'
date: 2012-08-14
permalink: /posts/2012/08/blog-post-1/
tags:
  - cool posts
  - category1
  - category2
---

## Attribution:

The information in this post is largely derived from StatQuest with Josh Starmer, who is an amazing YouTuber who discusses statistics. I highly recommend you check out his video on Entropy as well.

## Introduction

Hello there! Welcome to this post on Entropy. Entropy is a very important term that appears in many scenarios ranging from statistics to machine learning. In this post, we’ll go beyond the formulas and discuss the essence of entropy and what the numbers really mean. Let’s begin!

## What is Entropy?

So what is entropy? In essence, entropy is a number that quantifies similarities (or differences). Let’s take a look at an example.

## Example

Say we have two groups each composed of 10 children. In the first group, we have 9 girls and 1 boy, whereas in the second group, we have 5 girls and 5 boys. How would you quantify the similarities of the two groups? It’s quite obvious that the first group with 9 girls and 1 boy is more “similar” compared to that of the second group. In the first group, most of the children are of the same gender, therefore making it more similar in that aspect. In the second group, there’s an equal distribution of boys and girls, therefore making it not as similar. This is exactly what entropy can measure.

## Intuition

Entropy can range from 0 to 1. In the case of the second group where gender is equally distributed (the most different it can get), the entropy is 1. And as one gender gradually dominates the population (like in group 1), the entropy decreases to 0. That’s it! If you’re only interested in the intuition behind entropy, you’re free to go. But why not take a look at the math and examine how the formula of entropy was actually derived?

## The Formula of Entropy

You should know from textbooks and google that the entropy formula (of a random variable X) is:

$$
-\sum_x{P(X=x)log[P(X=x)]}
$$

Headings are cool
======

You can have many headings
======

Aren't headings cool?
------